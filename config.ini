[Data]
bert_model = 'bert-base-chinese'

[Network]
n_embed = 100
n_char_embed = 50
n_feat_embed = 100
n_bert_layers = 4
embed_dropout = .33
n_lstm_hidden = 400
n_lstm_layers = 3
lstm_dropout = .33
n_mlp = 500
mlp_dropout = .33

[Optimizer]
lr = 2e-3
mu = .9
nu = .9
epsilon = 1e-12
clip = 5.0
decay = .75
decay_epochs = 45

[Run]
batch_size = 5000
epochs = 1000
patience = 100
min_freq = 2
fix_len = 20